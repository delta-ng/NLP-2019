{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "## Removing all the links, hashtags and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "class StanceDetection:\n",
    "    def __init__(self,test,train):\n",
    "        self.testname=test\n",
    "        self.trainname=train\n",
    "    def html(self,sentence):\n",
    "        html=-1\n",
    "        dot=-1\n",
    "        final=[]\n",
    "        i=0\n",
    "        while(i<len(sentence)):\n",
    "            if(sentence[i][0].lower().find(\"http\")!=-1):\n",
    "                html=i\n",
    "            if((re.search(\"co\",sentence[i][0].lower()) or re.search(\"tco\",sentence[i][0].lower())) and html!=-1):\n",
    "                dot=i\n",
    "            if(html!=-1 and dot!=-1 and dot<=len(sentence)-2):\n",
    "                del sentence[html:dot+2]\n",
    "                i=html\n",
    "                html=-1\n",
    "                dot=-1\n",
    "            i+=1\n",
    "        return sentence\n",
    "    def process_file(self):\n",
    "        for u,ele in enumerate([self.testname,self.trainname]):\n",
    "            with open(ele) as file:\n",
    "                data = file.read()\n",
    "            linebyline=data.split('\\n')\n",
    "            sent_in=[]\n",
    "            sent_out=[]\n",
    "            dic={'ENG':0,'HIN':1,'O':2}\n",
    "            map_={}\n",
    "            i=0\n",
    "            while(i<len(linebyline)):\n",
    "                temp=linebyline[i].split()\n",
    "                if(len(temp)>=2):\n",
    "                    if(temp[0]=='meta' and len(temp)==3):\n",
    "                        map_[temp[1]]=len(sent_in)\n",
    "                        if(len(sent_in)!=0):\n",
    "                            sent_in[-1]=self.html(sent_in[-1])\n",
    "                        sent_in.append([])\n",
    "                        sent_out.append(temp[2])\n",
    "                    else:\n",
    "                        if(temp[0].find(\"@\")==len(temp[0])-1 or temp[0].find(\"#\")==len(temp[0])-1):\n",
    "                            i+=1\n",
    "                        else:\n",
    "                            data_clean=re.sub(\"[^a-zA-Z]+\", \"\",temp[0])\n",
    "                            if(len(data_clean)!=0):\n",
    "                                sent_in[-1].append((data_clean,dic[temp[1].upper()]))\n",
    "                i+=1\n",
    "            sent_in[-1]=self.html(sent_in[-1])\n",
    "            if(u==0):\n",
    "                self.test_in,self.test_out,self.test_map=sent_in,sent_out,map_\n",
    "            else:\n",
    "                self.train_in,self.train_out,self.train_map=sent_in,sent_out,map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hema', 1),\n",
       " ('I', 1),\n",
       " ('hate', 0),\n",
       " ('all', 0),\n",
       " ('type', 0),\n",
       " ('of', 0),\n",
       " ('parathes', 0),\n",
       " ('but', 0),\n",
       " ('I', 1),\n",
       " ('don', 1),\n",
       " ('t', 0),\n",
       " ('hate', 0),\n",
       " ('muli', 1),\n",
       " ('ke', 1),\n",
       " ('parathe', 1),\n",
       " ('Me', 0),\n",
       " ('farting', 0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj=StanceDetection(\"test.txt\",\"train.txt\")\n",
    "obj.process_file()\n",
    "obj.train_in[obj.train_map['9809']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "## Embedding is retrieved using FLARE for each word and padded then according to generate a sentence embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import BertEmbeddings\n",
    "X_train_flair = [Sentence(tweet) for tweet in obj.train_in]\n",
    "X_test_flair = [Sentence(tweet) for tweet in obj.train_out]\n",
    "embedding_bert = BertEmbeddings(\"bert-base-cased\")\n",
    "\n",
    "X_train_bert = []\n",
    "for sent in X_train_flair:\n",
    "    sent_emb = np.array(embedding_bert.embed(sent)[0])\n",
    "    emb = []\n",
    "    for token in sent_emb:\n",
    "        emb.append(np.array(token.embedding.cpu()))\n",
    "    X_train_bert.append(np.array(emb))\n",
    "\n",
    "X_test_bert = []\n",
    "for sent in X_test_flair:\n",
    "    sent_emb = np.array(embedding_bert.embed(sent)[0])\n",
    "    emb = []\n",
    "    for token in sent_emb:\n",
    "        emb.append(np.array(token.embedding.cpu()))\n",
    "    X_test_bert.append(np.array(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional,Flatten,GRU,GlobalMaxPool1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "ops.reset_default_graph()\n",
    "# import tensorflow as tf\n",
    "np_emb_train=np.load(\"FLARE_train.npy\",allow_pickle=1)\n",
    "np_emb_test=np.load(\"FLARE_test.npy\",allow_pickle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 3072)\n",
      "(1869,)\n"
     ]
    }
   ],
   "source": [
    "print(np_emb_train[0].shape)  \n",
    "print(np_emb_test.shape)  \n",
    "X_train = np_emb_train\n",
    "X_test = np_emb_test\n",
    "llist = []\n",
    "for i in X_train:\n",
    "      llist.append(torch.tensor(i[:31]))\n",
    "X_train = pad_sequence(llist, batch_first=True)\n",
    "llist = []\n",
    "for i in X_test:\n",
    "      llist.append(torch.tensor(i[:31]))\n",
    "X_test = pad_sequence(llist, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=np.load(\"train.npy\")\n",
    "Y_test=np.load(\"test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL\n",
    "## We used a Bi-directional LSTM with 100 elements and then a LSTM with 20 element then densed it to 3 elements using a 3rd layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15131 samples\n",
      "Epoch 1/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.9608 - acc: 0.5083 - f1_m: 0.3472 - precision_m: 0.5859 - recall_m: 0.2541\n",
      "Epoch 00001: loss improved from inf to 0.96077, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 98s 7ms/sample - loss: 0.9608 - acc: 0.5082 - f1_m: 0.3479 - precision_m: 0.5856 - recall_m: 0.2548\n",
      "Epoch 2/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.8654 - acc: 0.5835 - f1_m: 0.5184 - precision_m: 0.6444 - recall_m: 0.4347\n",
      "Epoch 00002: loss improved from 0.96077 to 0.86536, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 88s 6ms/sample - loss: 0.8654 - acc: 0.5834 - f1_m: 0.5174 - precision_m: 0.6461 - recall_m: 0.4330\n",
      "Epoch 3/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.8094 - acc: 0.6246 - f1_m: 0.5843 - precision_m: 0.6735 - recall_m: 0.5168\n",
      "Epoch 00003: loss improved from 0.86536 to 0.80935, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 94s 6ms/sample - loss: 0.8094 - acc: 0.6244 - f1_m: 0.5847 - precision_m: 0.6745 - recall_m: 0.5168\n",
      "Epoch 4/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.7647 - acc: 0.6559 - f1_m: 0.6263 - precision_m: 0.6958 - recall_m: 0.5698\n",
      "Epoch 00004: loss improved from 0.80935 to 0.76478, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 84s 6ms/sample - loss: 0.7648 - acc: 0.6560 - f1_m: 0.6263 - precision_m: 0.6961 - recall_m: 0.5695\n",
      "Epoch 5/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.7046 - acc: 0.6937 - f1_m: 0.6749 - precision_m: 0.7318 - recall_m: 0.6268\n",
      "Epoch 00005: loss improved from 0.76478 to 0.70478, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 92s 6ms/sample - loss: 0.7048 - acc: 0.6936 - f1_m: 0.6741 - precision_m: 0.7307 - recall_m: 0.6262\n"
     ]
    }
   ],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def LSTM_model():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128,input_shape=(31,3072),return_sequences=1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(20))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    filepath=\"lstm.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model.fit(X_train.numpy(), Y_train, epochs=5, batch_size=256,callbacks=callbacks_list)\n",
    "    return model\n",
    "model=LSTM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        388      105        40\n",
      "neutral         296      273       185\n",
      "positive        115      133       334\n",
      "\n",
      "\n",
      "Accuracy:  0.5323702514713751\n",
      "\n",
      " Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.73      0.58       533\n",
      "     neutral       0.53      0.36      0.43       754\n",
      "    positive       0.60      0.57      0.59       582\n",
      "\n",
      "    accuracy                           0.53      1869\n",
      "   macro avg       0.54      0.55      0.53      1869\n",
      "weighted avg       0.54      0.53      0.52      1869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report as clf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "y_dct = {'negative':0, \"neutral\":1,\"positive\":2}\n",
    "y_test_int = []\n",
    "for i in range(len(Y_test)):\n",
    "      y_test_int.append(list(Y_test[i]).index(1))\n",
    "target_names=['negative','neutral','positive']\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test_int, y_pred), columns=target_names, index=target_names)\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "\n",
    "print(df_cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy: \",accuracy_score(y_test_int, y_pred))\n",
    "print(\"\\n\",\"Report:\")\n",
    "print(clf(y_test_int, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional multiple                  3277824   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  16680     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  63        \n",
      "=================================================================\n",
      "Total params: 3,294,567\n",
      "Trainable params: 3,294,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
