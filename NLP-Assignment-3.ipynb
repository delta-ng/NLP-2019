{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "## Removing all the links, hashtags and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "class StanceDetection:\n",
    "    def __init__(self,test,train):\n",
    "        self.testname=test\n",
    "        self.trainname=train\n",
    "    def html(self,sentence):\n",
    "        html=-1\n",
    "        dot=-1\n",
    "        final=[]\n",
    "        i=0\n",
    "        while(i<len(sentence)):\n",
    "            if(sentence[i][0].lower().find(\"http\")!=-1):\n",
    "                html=i\n",
    "            if((re.search(\"co\",sentence[i][0].lower()) or re.search(\"tco\",sentence[i][0].lower())) and html!=-1):\n",
    "                dot=i\n",
    "            if(html!=-1 and dot!=-1 and dot<=len(sentence)-2):\n",
    "                del sentence[html:dot+2]\n",
    "                i=html\n",
    "                html=-1\n",
    "                dot=-1\n",
    "            i+=1\n",
    "        return sentence\n",
    "    def process_file(self):\n",
    "        for u,ele in enumerate([self.testname,self.trainname]):\n",
    "            with open(ele) as file:\n",
    "                data = file.read()\n",
    "            linebyline=data.split('\\n')\n",
    "            sent_in=[]\n",
    "            sent_out=[]\n",
    "            dic={'ENG':0,'HIN':1,'O':2}\n",
    "            map_={}\n",
    "            i=0\n",
    "            while(i<len(linebyline)):\n",
    "                temp=linebyline[i].split()\n",
    "                if(len(temp)>=2):\n",
    "                    if(temp[0]=='meta' and len(temp)==3):\n",
    "                        map_[temp[1]]=len(sent_in)\n",
    "                        if(len(sent_in)!=0):\n",
    "                            sent_in[-1]=self.html(sent_in[-1])\n",
    "                        sent_in.append([])\n",
    "                        sent_out.append(temp[2])\n",
    "                    else:\n",
    "                        if(temp[0].find(\"@\")==len(temp[0])-1 or temp[0].find(\"#\")==len(temp[0])-1):\n",
    "                            i+=1\n",
    "                        else:\n",
    "                            data_clean=re.sub(\"[^a-zA-Z]+\", \"\",temp[0])\n",
    "                            if(len(data_clean)!=0):\n",
    "                                sent_in[-1].append((data_clean,dic[temp[1].upper()]))\n",
    "                i+=1\n",
    "            sent_in[-1]=self.html(sent_in[-1])\n",
    "            if(u==0):\n",
    "                self.test_in,self.test_out,self.test_map=sent_in,sent_out,map_\n",
    "            else:\n",
    "                self.train_in,self.train_out,self.train_map=sent_in,sent_out,map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hema', 1),\n",
       " ('I', 1),\n",
       " ('hate', 0),\n",
       " ('all', 0),\n",
       " ('type', 0),\n",
       " ('of', 0),\n",
       " ('parathes', 0),\n",
       " ('but', 0),\n",
       " ('I', 1),\n",
       " ('don', 1),\n",
       " ('t', 0),\n",
       " ('hate', 0),\n",
       " ('muli', 1),\n",
       " ('ke', 1),\n",
       " ('parathe', 1),\n",
       " ('Me', 0),\n",
       " ('farting', 0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj=StanceDetection(\"test.txt\",\"train.txt\")\n",
    "obj.process_file()\n",
    "obj.train_in[obj.train_map['9809']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "## Embedding is retrieved using FLARE for each word and padded then according to generate a sentence embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional,Flatten,GRU,GlobalMaxPool1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "ops.reset_default_graph()\n",
    "# import tensorflow as tf\n",
    "np_emb_train=np.load(\"FLARE_train.npy\",allow_pickle=1)\n",
    "np_emb_test=np.load(\"FLARE_test.npy\",allow_pickle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 3072)\n",
      "(1869,)\n"
     ]
    }
   ],
   "source": [
    "print(np_emb_train[0].shape)  \n",
    "print(np_emb_test.shape)  \n",
    "X_train = np_emb_train\n",
    "X_test = np_emb_test\n",
    "llist = []\n",
    "for i in X_train:\n",
    "      llist.append(torch.tensor(i[:31]))\n",
    "X_train = pad_sequence(llist, batch_first=True)\n",
    "llist = []\n",
    "for i in X_test:\n",
    "      llist.append(torch.tensor(i[:31]))\n",
    "X_test = pad_sequence(llist, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=np.load(\"train.npy\")\n",
    "Y_test=np.load(\"test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL\n",
    "## We used a Bi-directional LSTM with 100 elements and then a LSTM with 20 element then densed it to 3 elements using a 3rd layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15131 samples\n",
      "Epoch 1/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.9716 - acc: 0.4997 - f1_m: 0.3221 - precision_m: 0.5913 - recall_m: 0.2352\n",
      "Epoch 00001: loss improved from inf to 0.97141, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 98s 6ms/sample - loss: 0.9714 - acc: 0.4999 - f1_m: 0.3252 - precision_m: 0.5929 - recall_m: 0.2380\n",
      "Epoch 2/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.8701 - acc: 0.5766 - f1_m: 0.5103 - precision_m: 0.6326 - recall_m: 0.4291\n",
      "Epoch 00002: loss improved from 0.97141 to 0.87011, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 95s 6ms/sample - loss: 0.8701 - acc: 0.5766 - f1_m: 0.5103 - precision_m: 0.6335 - recall_m: 0.4287\n",
      "Epoch 3/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.8347 - acc: 0.6082 - f1_m: 0.5568 - precision_m: 0.6625 - recall_m: 0.4814\n",
      "Epoch 00003: loss improved from 0.87011 to 0.83482, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 88s 6ms/sample - loss: 0.8348 - acc: 0.6082 - f1_m: 0.5560 - precision_m: 0.6615 - recall_m: 0.4808\n",
      "Epoch 4/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.7854 - acc: 0.6424 - f1_m: 0.6095 - precision_m: 0.6885 - recall_m: 0.5474\n",
      "Epoch 00004: loss improved from 0.83482 to 0.78541, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 81s 5ms/sample - loss: 0.7854 - acc: 0.6424 - f1_m: 0.6087 - precision_m: 0.6885 - recall_m: 0.5463\n",
      "Epoch 5/5\n",
      "15104/15131 [============================>.] - ETA: 0s - loss: 0.7444 - acc: 0.6704 - f1_m: 0.6425 - precision_m: 0.7139 - recall_m: 0.5849\n",
      "Epoch 00005: loss improved from 0.78541 to 0.74396, saving model to lstm.hdf5\n",
      "15131/15131 [==============================] - 85s 6ms/sample - loss: 0.7440 - acc: 0.6707 - f1_m: 0.6449 - precision_m: 0.7159 - recall_m: 0.5875\n"
     ]
    }
   ],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def LSTM_model():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128,input_shape=(31,3072),return_sequences=1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(20))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    filepath=\"lstm.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model.fit(X_train.numpy(), Y_train, epochs=5, batch_size=256,callbacks=callbacks_list)\n",
    "    return model\n",
    "model=LSTM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test.numpy(), Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.52969503, 0.51582956, 0.54311556, 0.49189213)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, f1_score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional multiple                  3277824   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  16680     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  63        \n",
      "=================================================================\n",
      "Total params: 3,294,567\n",
      "Trainable params: 3,294,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
